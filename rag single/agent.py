"""
ä½¿ç”¨Agentæ¶æ„ï¼Œè‡ªä¸»æœç´¢çŸ¥è¯†åº“å¹¶ç”Ÿæˆè¯¦ç»†è§£å†³æ–¹æ¡ˆ
"""
import json
from typing import Dict, List, Any
from langchain.tools import tool
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from knowledge_base.kb import KnowledgeBase


class Agent:
    """è§„åˆ’Agentï¼šåŸºäºçŸ¥è¯†åº“å’Œå·¥å…·æ¥å£json schemaï¼Œç”Ÿæˆåˆ†æ­¥ã€ç»“æ„åŒ–çš„è§£å†³æ–¹æ¡ˆè®¡åˆ’"""
    
    def __init__(self, knowledge_base: KnowledgeBase, tools_schema_path: str = None, model_name: str = "qwen-max", api_key: str = None, base_url: str = None):
        self.kb = knowledge_base
        
        # é»˜è®¤åœ¨å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•æŸ¥æ‰¾ tools_schema.json
        if tools_schema_path is None:
            import os
            current_dir = os.path.dirname(os.path.abspath(__file__))
            tools_schema_path = os.path.join(current_dir, "tools_schema.json")
            
        self.tools_schema = self._load_tools_schema(tools_schema_path)
        
        # åˆ›å»ºçŸ¥è¯†åº“æœç´¢å·¥å…·
        @tool
        def search_knowledge(query: str) -> str:
            """
            æœç´¢çŸ¥è¯†åº“è·å–ç›¸å…³ä¿¡æ¯ã€‚
            """
            return self.kb.retrieve(query, k=3)
        

        self.tools = [search_knowledge]

        # åˆå§‹åŒ–LLMå’ŒAgent
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=0.1,
            api_key=api_key or "your-api-key-here",
            base_url=base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
        
        # è®¾ç½®è§„åˆ’Agent
        self._setup_planning_agent()
    
    def _load_tools_schema(self, schema_path: str) -> List[Dict]:
        """åŠ è½½å·¥å…·schema"""
        try:
            with open(schema_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è­¦å‘Šï¼šæ— æ³•åŠ è½½å·¥å…·schema ({e})ï¼Œå°†ä½¿ç”¨ç©ºschema")
            return []
    
    def _setup_planning_agent(self):
        """è®¾ç½®è§„åˆ’Agent"""   
        system_prompt = f"""ä½ æ˜¯solution planingä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·é—®é¢˜ï¼Œåˆ¶å®šè¯¦ç»†çš„åˆ†æ­¥è§£å†³æ–¹æ¡ˆè®¡åˆ’ã€‚ç®€å•çš„é—®é¢˜å¯ä»¥ç›´æ¥ç”¨llmè®¡ç®—è§£å†³ï¼Œå¤æ‚é—®é¢˜éœ€è¦æŸ¥è¯¢çŸ¥è¯†åº“å¹¶è°ƒç”¨å·¥å…·ã€‚

å¯ç”¨å·¥å…·ï¼š
- search_knowledge: æŸ¥è¯¢çŸ¥è¯†åº“è·å–ç›¸å…³æ–¹æ³•å’ŒåŸç†


å·¥ä½œæµç¨‹ï¼š
1. é‡åˆ°ä¸æ‡‚çš„é—®é¢˜æˆ–æ¦‚å¿µ â†’ è°ƒç”¨search_knowledgeæŸ¥è¯¢çŸ¥è¯†åº“
2. æœä¸åˆ°æ—¶å°è¯•åˆ†æé—®é¢˜æ”¹å˜queryæœç´¢é—®é¢˜ï¼ŒåŠ¡å¿…æ ¹æ®çŸ¥è¯†æ¥å†³ç­–ï¼Œè‡³å°‘è¦æœåˆ°ä¸€æ¬¡
3. æ ¹æ®è¿”å›çš„ä¿¡æ¯åˆ¤æ–­ï¼Œåˆ¶å®šè¯¦ç»†æ‰§è¡Œè®¡åˆ’ï¼š
   - å¦‚æœçŸ¥è¯†åº“è¿”å›äº†æ–¹æ³•æè¿° â†’ ç†è§£åå‘ç°èƒ½ç›´æ¥é llmè®¡ç®—--æ·»åŠ llm_reasoning step; å¦‚æœä¾ç„¶ä¸æ¸…æ¥šï¼Œç»§ç»­æŸ¥è¯¢çŸ¥è¯†åº“
4. æ ¹æ®å·¥å…·æˆ–llm_reasoningçš„é¢„æœŸè¿”å›ç»§ç»­åˆ†ææ˜¯å¦è¾¾åˆ°ç›®çš„ï¼Œä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ
5. é€’å½’å¤„ç†æ‰€æœ‰å­é—®é¢˜ç›´åˆ°èƒ½å¤Ÿå®Œå…¨è§£å†³ç”¨æˆ·é—®é¢˜ï¼Œè·å¾—æƒ³è¦çš„ç»“æœ
6. è¾“å‡ºå‰åˆ†æè®¡åˆ’è¯„ä¼°æ˜¯å¦æ¸…æ¥šæ¯ä¸€æ­¥ï¼Œæ˜¯å¦è§£å†³ç”¨æˆ·é—®é¢˜ï¼Œæœ€ç»ˆè¾“å‡ºæ˜¯å¦ç®€å•æ˜“æ‡‚ï¼Œå¦åˆ™é‡å¤ä¸Šé¢æ­¥éª¤
7. å½“ä½ å¾—åˆ°æœ€ç»ˆç»“æœæ—¶ï¼Œè¯·åŠ¡å¿…ä»¥ "Final Answer:" å¼€å¤´è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

è¯·åŠ¡å¿…åœ¨æ€è€ƒè¿‡ç¨‹ä¸­æ¸…æ™°åœ°æè¿°ä½ çš„æ¯ä¸€æ­¥è¡ŒåŠ¨ï¼Œä¾‹å¦‚ï¼šâ€œæˆ‘å°†é¦–å…ˆæœç´¢å…³äº...çš„çŸ¥è¯†â€ï¼Œâ€œæ ¹æ®æœç´¢ç»“æœï¼Œæˆ‘å‘ç°...ï¼Œæ¥ä¸‹æ¥æˆ‘å°†...â€ã€‚

ä¾‹å­ï¼š
ç”¨æˆ·: "é…åˆ¶RGB(128,20,190)é¢œè‰²"
â†’ search_knowledge("RGBé¢œè‰²é…åˆ¶")
â† è¿”å›: éœ€è¦RGBâ†’CMYã€è®¡ç®—æ¯”ä¾‹ã€å¤šç»„åˆ†æ··åˆ
â†’ search_knowledge("RGBè½¬CMY")
â† è¿”å›: å…¬å¼C=255-R...
â†’ æ·»åŠ ç›´æ¥è®¡ç®—æ­¥éª¤
â†’ åˆ†æä¸‹ä¸€æ­¥"è®¡ç®—æ¯”ä¾‹"
"""

        # åˆ›å»ºå·¥å…·åˆ—è¡¨
        tools = self.tools
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])
        
        # åˆ›å»ºAgent
        agent = create_openai_tools_agent(
            llm=self.llm,
            tools=tools,
            prompt=prompt
        )
        
        # åˆ›å»ºAgentæ‰§è¡Œå™¨
        self.agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            max_iterations=10,
            handle_parsing_errors=True
        )
       
    def run(self, user_input: str) -> Dict[str, Any]:
        """
        æ ¹æ®ç”¨æˆ·è¾“å…¥åˆ›å»ºè¯¦ç»†çš„è§£å†³æ–¹æ¡ˆè®¡åˆ’
        ä½¿ç”¨Agentæ¶æ„ï¼Œè®©LLMè‡ªä¸»å†³å®šä½•æ—¶æœç´¢çŸ¥è¯†åº“
        """
        try:
            # ä½¿ç”¨Agentæ‰§è¡Œå™¨å¤„ç†ç”¨æˆ·è¾“å…¥
            result = self.agent_executor.invoke({
                "input": f"è¯·ä¸ºä»¥ä¸‹é—®é¢˜åˆ¶å®šè¯¦ç»†çš„è§£å†³æ–¹æ¡ˆè®¡åˆ’ï¼š\n\n{user_input}"
            })
            return result
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def run_stream(self, user_input: str):
        """
        å¼‚æ­¥æµå¼è¾“å‡º Agent çš„æ€è€ƒè¿‡ç¨‹å’Œç»“æœ
        """
        # ä¿æŒä¸ run æ–¹æ³•ä¸€è‡´çš„ prompt æ„å»º
        full_input = f"è¯·ä¸ºä»¥ä¸‹é—®é¢˜åˆ¶å®šè¯¦ç»†çš„è§£å†³æ–¹æ¡ˆè®¡åˆ’ï¼š\n\n{user_input}"
        
        try:
            # è®°å½•å®Œæ•´çš„æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆ
            buffer = ""
            final_answer_started = False
            action_started = False
            
            async for event in self.agent_executor.astream_events(
                {"input": full_input},
                version="v1"
            ):
                kind = event["event"]
                
                # æ•è·å·¥å…·è°ƒç”¨å¼€å§‹
                if kind == "on_tool_start":
                    # å¦‚æœæœ‰æœªå‘é€çš„ç¼“å†²å†…å®¹ï¼ˆé€šå¸¸æ˜¯æ€è€ƒï¼‰ï¼Œå…ˆå‘é€
                    if buffer.strip() and not action_started:
                        # æ¸…ç† "Thought:" å‰ç¼€
                        content_to_send = buffer.replace("Thought:", "").replace("Thought", "").strip()
                        if content_to_send:
                            yield {"type": "thought_chunk", "content": content_to_send}
                    buffer = ""
                    
                    action = event['data'].get('input')
                    # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ LangChain
                    if hasattr(action, 'tool'):
                        tool_name = action.tool
                        tool_input = action.tool_input
                    else:
                        tool_name = event['name']
                        tool_input = event['data'].get('input')
                        
                    yield {
                        "type": "thought",
                        "content": f"æ­£åœ¨ä½¿ç”¨ {tool_name}...",
                        "tool": tool_name,
                        "tool_input": tool_input
                    }
                
                # æ•è·æ¨¡å‹è¾“å‡ºçš„ Token (å®ç°æ‰“å­—æœºæ•ˆæœ)
                elif kind == "on_chat_model_stream":
                    content = event["data"]["chunk"].content
                    if not content:
                        continue
                    
                    # 1. å¦‚æœå·²ç»è¿›å…¥ Final Answer é˜¶æ®µï¼Œç›´æ¥ä½œä¸ºå›ç­”å‘é€
                    if final_answer_started:
                        yield {"type": "answer_chunk", "content": content}
                        continue

                    # 2. å¦‚æœå·²ç»è¿›å…¥ Action é˜¶æ®µï¼ˆæ­£åœ¨ç”Ÿæˆå·¥å…·è°ƒç”¨ä»£ç ï¼‰ï¼Œåˆ™ä¸å‘é€ç»™å‰ç«¯ï¼ˆéšè— Action å£°æ˜ï¼‰
                    if action_started:
                        continue

                    # 3. ç¼“å†²å†…å®¹ä»¥è¿›è¡Œæ£€æµ‹
                    buffer += content
                    
                    # æ£€æµ‹ Final Answer
                    if "Final Answer" in buffer:
                        final_answer_started = True
                        # æ‰¾åˆ°åˆ†å‰²ç‚¹
                        split_marker = "Final Answer:" if "Final Answer:" in buffer else "Final Answer"
                        parts = buffer.split(split_marker, 1)
                        
                        # åˆ†å‰²ç‚¹ä¹‹å‰çš„å†…å®¹å±äºæ€è€ƒ
                        thought_content = parts[0].replace("Thought:", "").replace("Thought", "").strip()
                        if thought_content:
                            yield {"type": "thought_chunk", "content": thought_content}
                        
                        # åˆ†å‰²ç‚¹ä¹‹åçš„å†…å®¹å±äºå›ç­”
                        if len(parts) > 1 and parts[1]:
                            yield {"type": "answer_chunk", "content": parts[1]}
                        
                        buffer = "" # æ¸…ç©ºç¼“å†²
                        continue

                    # æ£€æµ‹ Action (éšè— Action: ... åŠå…¶åçš„å†…å®¹ç›´åˆ°å·¥å…·è°ƒç”¨)
                    if "Action" in buffer:
                        # æ‰¾åˆ° Action çš„ä½ç½®
                        action_index = buffer.find("Action")
                        # Action ä¹‹å‰çš„å†…å®¹æ˜¯æ€è€ƒ
                        thought_content = buffer[:action_index].replace("Thought:", "").replace("Thought", "").strip()
                        if thought_content:
                            yield {"type": "thought_chunk", "content": thought_content}
                        
                        action_started = True
                        buffer = "" # æ¸…ç©ºç¼“å†²ï¼Œåç»­çš„ Action å†…å®¹å°†è¢«å¿½ç•¥
                        continue

                    # å¦‚æœç¼“å†²åŒºè¿‡å¤§ä¸”æ²¡æœ‰ç‰¹æ®Šæ ‡è®°ï¼Œåˆ™å°†å‰é¢çš„å†…å®¹ä½œä¸ºæ€è€ƒå‘é€
                    # ä¿ç•™æœ€åä¸€éƒ¨åˆ†ä»¥é˜²æ ‡è®°è¢«åˆ‡æ–­ (ä¾‹å¦‚ "Final A" æˆ– "Act")
                    if len(buffer) > 20:
                        to_send = buffer[:-15]
                        buffer = buffer[-15:]
                        # åªæœ‰å½“ to_send ä¸ä»…ä»…æ˜¯ "Thought" æ—¶æ‰å‘é€ï¼Œé¿å…é‡å¤
                        clean_send = to_send.replace("Thought:", "").replace("Thought", "").strip()
                        if clean_send:
                            yield {"type": "thought_chunk", "content": clean_send}
                
                # æ•è·å·¥å…·æ‰§è¡Œç»“æŸ
                elif kind == "on_tool_end":
                    action_started = False # Action ç»“æŸï¼Œæ¢å¤æ­£å¸¸æµå¼è¾“å‡ºï¼ˆé€šå¸¸æ¥ä¸‹æ¥æ˜¯ Observationï¼‰
                    buffer = "" # ç¡®ä¿ç¼“å†²æ¸…ç©º
                        
                    output = event['data'].get('output')
                    yield {
                        "type": "observation",
                        "content": str(output) if output else "æ— ç»“æœ",
                        "tool": event['name']
                    }
                
                # æ•è·æœ€ç»ˆè¾“å‡º
                elif kind == "on_agent_finish":
                    # ç¡®ä¿æ‰€æœ‰ç¼“å†²éƒ½å·²å¤„ç†
                    if buffer and not final_answer_started and not action_started:
                         # å¦‚æœç¼“å†²åŒºåŒ…å« Final Answerï¼Œè¯´æ˜å®ƒæ˜¯å›ç­”çš„ä¸€éƒ¨åˆ†ï¼Œä¸è¦ä½œä¸ºæ€è€ƒå‘é€
                         if "Final Answer" in buffer:
                             pass
                         else:
                             clean_buffer = buffer.replace("Thought:", "").replace("Thought", "").strip()
                             if clean_buffer:
                                yield {"type": "thought_chunk", "content": clean_buffer}
                    
                    output = event["data"]["output"]
                    # æ¸…ç† Final Answer æ ‡è®°ï¼Œé˜²æ­¢é‡å¤
                    clean_output = output.replace("Final Answer:", "").replace("Final Answer", "").strip()
                    yield {
                        "type": "final_answer",
                        "content": clean_output
                    }
        except Exception as e:
            yield {"type": "error", "content": str(e)}
    
def test_agent():
    """æµ‹è¯•è§„åˆ’Agent"""
    # åˆå§‹åŒ–çŸ¥è¯†åº“å’Œè§„åˆ’Agent
    kb = KnowledgeBase("knowledge_base")
    agent = Agent(kb)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "é…’ç²¾ç¨€é‡Šæµ‹è¯•",
            "input": "æˆ‘éœ€è¦å°†95%çš„é…’ç²¾ç¨€é‡Šåˆ°70%"
        },
        {
            "name": "å¤šç»„åˆ†æ··åˆæµ‹è¯•", 
            "input": "æˆ‘éœ€è¦åˆ¶å¤‡å«æœ‰0.15æµ“åº¦NaClå’Œ0.25æµ“åº¦è‘¡è„ç³–çš„æ··åˆæ¶²ã€‚ç°åœ¨æœ‰çº¯æ°´ã€30%NaClæº¶æ¶²å’Œ60%è‘¡è„ç³–æº¶æ¶²"
        },
        {
            "name": "é¢œè‰²é…åˆ¶æµ‹è¯•",
            "input": "é…åˆ¶RGB(150,20,190)çš„é¢œè‰²ï¼Œk=0.6"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ¯ è§„åˆ’æµ‹è¯• {i}: {test_case['name']}")
        print(f"{'='*80}")
        print(f"é—®é¢˜: {test_case['input']}")
        print("-" * 80)
        
        # è°ƒç”¨
        result = agent.run(test_case['input'])
        print(result)
        

        
        print("-" * 80)
        input("\næŒ‰Enterç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")


if __name__ == "__main__":
    test_agent()