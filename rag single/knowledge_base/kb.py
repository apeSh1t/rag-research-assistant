from pathlib import Path
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings

class KnowledgeBase:
    def __init__(self, kb_dir: str = "knowledge_base", use_english: bool = True):
        self.kb_dir = Path(kb_dir)
        self.use_english = use_english
        self.embedding_model = SentenceTransformerEmbeddings(
            model_name="BAAI/bge-base-en-v1.5"  # ä½¿ç”¨æ›´ä¼˜ç§€çš„è‹±æ–‡æ£€ç´¢æ¨¡å‹
        )
        self.vector_store = None
        self._load_vector_store()
    
    def _load_vector_store(self):
        # æ ¹æ®è¯­è¨€é€‰æ‹©ä¸åŒçš„å‘é‡åº“ç›®å½•
        if self.use_english:
            persist_dir = self.kb_dir.parent / "chroma_db_en"
            collection_name = "mixing_kb_en"
        else:
            persist_dir = self.kb_dir.parent / "chroma_db"
            collection_name = "mixing_kb"
        
        if not persist_dir.exists():
            raise FileNotFoundError(
                f"Vector store does not exist: {persist_dir}\n"
                "Please run: python knowledge_base/build_index.py first"
            )
        
        self.vector_store = Chroma(
            collection_name=collection_name,
            embedding_function=self.embedding_model,
            persist_directory=str(persist_dir)
        )
    
    def retrieve(self, query: str, k: int = 3) -> str:
        """æ£€ç´¢çŸ¥è¯†åº“"""
        if self.vector_store is None:
            return "çŸ¥è¯†åº“æœªåŠ è½½" if not self.use_english else "Knowledge base not loaded"
        
        results = self.vector_store.similarity_search_with_score(query, k=k)
        
        if not results:
            return f"æœªæ‰¾åˆ°ä¸'{query}'ç›¸å…³çš„ä¿¡æ¯" if not self.use_english else f"No information found for '{query}'"
        
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” Query: '{query}' - Search results:")
        for i, (doc, score) in enumerate(results):
            title = doc.metadata.get('title', 'Unknown')
            print(f"  {i+1}. Score: {score:.4f} - {title}")
        
        # æ·»åŠ ç›¸ä¼¼åº¦è¿‡æ»¤ï¼Œåªè¿”å›é«˜è´¨é‡åŒ¹é…
        formatted = "\n\n".join([
            f"ã€{doc.metadata.get('title', 'æœªå‘½å')}ã€‘(Score: {score:.4f})\n{doc.page_content}"
            for doc, score in results if score < 1.0  # è°ƒæ•´é˜ˆå€¼ä»¥è¿‡æ»¤ä½è´¨é‡åŒ¹é…
        ])
        
        return formatted if formatted else f"æœªæ‰¾åˆ°ä¸'{query}'é«˜åº¦ç›¸å…³çš„ä¿¡æ¯"
    
    def list_documents(self):
        """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£"""
        if self.vector_store is None:
            return "çŸ¥è¯†åº“æœªåŠ è½½"
        
        try:
            # è·å–æ‰€æœ‰æ–‡æ¡£ä¿¡æ¯
            all_docs = self.vector_store.get()
            if not all_docs['metadatas']:
                return "çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ–‡æ¡£"
            
            titles = [meta.get('title', 'Unknown') for meta in all_docs['metadatas']]
            return f"çŸ¥è¯†åº“åŒ…å« {len(titles)} ä¸ªæ–‡æ¡£:\n" + "\n".join(f"- {title}" for title in titles)
        except Exception as e:
            return f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}"